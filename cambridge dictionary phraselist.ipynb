{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11567"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=open('C:/Users/gartl/jupyter_mycode/data folder/cambridge_phrase.txt',encoding='utf-8').readlines() #put your address\n",
    "phrase=[i.strip().lower() for i in phrase]\n",
    "phrase=[re.sub(\"[\\#@;?:<>.!{}`+=~|]\",'',i) for i in phrase]\n",
    "phrase=list(set(phrase))\n",
    "len(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"what's up\"]\n",
      "['what’s eating someone']\n",
      "[\"it'll cost you\"]\n",
      "['something like']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in phrase if i==\"what's up\"])\n",
    "print([i for i in phrase if i==\"what’s eating someone\"])\n",
    "print([i for i in phrase if i==\"it'll cost you\"])\n",
    "print([i for i in phrase if i=='something like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=[re.sub('’',\"'\",i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"how's tricks\", \"how's life (treating you)\"]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in phrase if re.search(\"how's\", i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_place(cleaned): #regard common contractions as two words. in this cast 's == is, 'll == will etc..\n",
    "    cleaned = re.sub(\"what's\",\"what 's\",cleaned)\n",
    "    cleaned = re.sub(\"how's\",\"how 's\",cleaned)\n",
    "    cleaned = re.sub(\"why's\",\"why 's\",cleaned)\n",
    "    cleaned = re.sub(\"where's\",\"where 's\",cleaned)\n",
    "    cleaned = re.sub(\"when's\",\"when 's\",cleaned)\n",
    "    cleaned = re.sub(\"who's\",\"who 's\",cleaned)\n",
    "    cleaned = re.sub(\"it's\",\"it 's\",cleaned)\n",
    "    cleaned = re.sub(\"can't\", \"ca n't\",cleaned)\n",
    "    cleaned = re.sub(\"won't\", \"wo n't\",cleaned)\n",
    "    cleaned = re.sub(\"it'll\", \"it 'll\",cleaned)\n",
    "    cleaned = re.sub(\"we'll\", \"we 'll\",cleaned)\n",
    "    cleaned = re.sub(\"i'll\", \"i 'll\",cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=[space_place(i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"what 's eating someone\"]\n",
      "[\"i/we 'll (have to) see\", \"i 'll/we 'll cross that bridge when i/we come/get to it\", \"we 'll (soon) see about that\"]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in phrase if i==\"what 's eating someone\"])\n",
    "print([i for i in phrase if re.search(\"we 'll\", i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bracket(x):\n",
    "    bracket_list=[]\n",
    "    if re.search('\\(',x)!=None: #find phrases that include bracket\n",
    "        string=x.split()\n",
    "        bracket=[]\n",
    "        for i in string:\n",
    "            if re.search('\\(',i)==None and re.search('\\)',i)==None: #extract words which are outside bracket. ex. finish (sth) up => finish up                                                            \n",
    "                bracket.append(i)\n",
    "        text=' '.join(bracket)\n",
    "        bracket_list.append(text)\n",
    "    return bracket_list\n",
    "                \n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in touch', 'now and then/again', 'the straight and narrow', 'finish up', 'in the scheme of things', 'on the money', 'pass belief', 'stew your own', 'wash out', 'a nip and a tuck', 'lay off', 'daggers drawn', 'throw a curve', 'business as usual', 'the to come', 'a bitter pill', 'trust sb do', 'change up', 'in all my days', 'have your head screwed on right']\n"
     ]
    }
   ],
   "source": [
    "bracket=[bracket(i) for i in phrase]\n",
    "bracket=[i for i in bracket if len(i)>0] #eliminate empty list\n",
    "bracket=[j for i in bracket for j in i] #2d list -> 1d list\n",
    "bracket=[i for i in bracket if len(i.split())>1]# eliminate one word results since these are not meet our notion of MWE \n",
    "print(bracket[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11567\n",
      "11567\n",
      "11566\n",
      "12306\n"
     ]
    }
   ],
   "source": [
    "print(len(phrase))\n",
    "phrase=[re.sub(\"[()]\",'',i) for i in phrase]\n",
    "print(len(phrase))\n",
    "print(len(set(phrase)))\n",
    "phrase=list(set(phrase+bracket))\n",
    "print(len(phrase))\n",
    "#phrase=list(set(phrase+different_bracket))\n",
    "#print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slash(x):\n",
    "    #slashes=[]\n",
    "    slash_list=[]\n",
    "    if re.search('/',x)!=None: #find phrases that include slash\n",
    "        string=x.split()\n",
    "        for i,x in enumerate(string):\n",
    "            if re.search('/',x)!=None:#find the wordstring that include slash in phrase \n",
    "                slash=x.split('/') #divide it by slash\n",
    "                #print(slash)\n",
    "                for w in slash: #make separate headword, ex) push sth up/down => push sth up, push sth down\n",
    "                    string[i]=w \n",
    "                    #print(string[i])\n",
    "                    text=' '.join(string)\n",
    "                    slash_list.append(text)\n",
    "                    #print(text)\n",
    "    return slash_list\n",
    "                    \n",
    "slashed=[slash(i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "3926\n"
     ]
    }
   ],
   "source": [
    "slashed=[slash(i) for i in phrase] #find phrases include slash\n",
    "slashed=[i for i in slashed if len(i)>0] #eliminate blank lists\n",
    "slashed=[j for i in slashed for j in i] # make 2d nested list into 1d list\n",
    "anti_slashed=[i for i in slashed if re.search('/',i)!=None] #phrases that include two or more slashes\n",
    "slashed=[i for i in slashed if re.search('/',i)==None]\n",
    "anti_slashed=list(set(anti_slashed))\n",
    "slashed=list(set(slashed))\n",
    "print(len(anti_slashed))\n",
    "print(len(slashed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12306\n",
      "1946\n",
      "10360\n",
      "13867\n"
     ]
    }
   ],
   "source": [
    "print(len(phrase))\n",
    "print(len([i for i in phrase if re.search('/',i)!=None]))\n",
    "phrase=[i for i in phrase if re.search('/',i)==None]\n",
    "print(len(phrase))\n",
    "phrase=list(set(phrase+slashed))\n",
    "print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pale in comparison with something', 'amount to sth', 'bend to sth', 'couple something with something', 'dine on sth', 'get a jump on sth', 'tie someone to something', 'a blitz on sth', 'hand back something', 'insinuate yourself into sth']\n",
      "['freeze out someone', 'vest in sb', 'happen upon sb', 'impress sth upon sb', 'dispose of sb', 'thumb your nose at someone', 'get the wind up sb', 'keep sth off sb', 'rid sth of sb', 'become of sb']\n",
      "['something or other', 'something hangs in the balance', 'something takes the cake', 'something rears its head', 'sth rocks', 'something goes for someone else', 'something is like looking for a needle in a haystack', 'something is a matter of doing something', 'something sticks in your mind', 'something speaks for itself']\n",
      "[\"someone can dish it out but he or she ca n't take it\", \"sb's biological clock is ticking\", \"sb's mind races\", 'sb does things to you', \"someone's true colors\", \"someone's heart is in the right place\", \"sb's pulse races\", \"sb's eyes are bigger than their belly\", \"someone's number is up\", \"sb's frame of mind\"]\n",
      "2672\n",
      "1164\n",
      "41\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "# this code find headwords that first or last word is sth/something and sb/somebody and eliminate sth/something and sb/somebody\n",
    "#It's because actual phrases don't include sth/something and sb/somebody\n",
    "sth_end=[i for i in phrase if i.endswith('sth') or i.endswith('something')]   \n",
    "print(sth_end[:10])\n",
    "\n",
    "sb_end=[i for i in phrase if i.endswith('sb') or i.endswith('someone')]\n",
    "print(sb_end[:10])\n",
    "\n",
    "sth_start=[i for i in phrase if i.startswith('sth') or i.startswith('something')]\n",
    "print(sth_start[:10])\n",
    "\n",
    "sb_start=[i for i in phrase if i.startswith('sb') or i.startswith('someone')]\n",
    "print(sb_start[:10])\n",
    "\n",
    "print(len(sth_end))\n",
    "print(len(sb_end))\n",
    "print(len(sth_start))\n",
    "print(len(sb_start))\n",
    "\n",
    "some=sth_end+sb_end+sth_start+sb_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9934\n",
      "3943\n"
     ]
    }
   ],
   "source": [
    "phrase=[i for i in phrase if i not in some]\n",
    "print(len(phrase))\n",
    "sth_end=[' '.join(i.split()[:-1]) for i in sth_end]\n",
    "sb_end=[' '.join(i.split()[:-1]) for i in sb_end]\n",
    "some_cleaned=sth_end+sb_end+sth_start+sb_start\n",
    "print(len(some_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sb and sth into certain objective pronoun \n",
    "#Since sth and sb (or something and somebody)in objective pronoun position are not used in real text,\n",
    "#therefore phrases can't be extracted well if they are not changed into objective pronouns.\n",
    "\n",
    "phrase_it=[re.sub('(sth|something)','it',i) for i in phrase]\n",
    "phrase_this=[re.sub('(sth|something)','this',i) for i in phrase]\n",
    "phrase_that=[re.sub('(sth|something)','that',i) for i in phrase]\n",
    "phrase_these=[re.sub('(sth|something)','these',i) for i in phrase]\n",
    "phrase_those=[re.sub('(sth|something)','those',i) for i in phrase]\n",
    "phrase_him=[re.sub('(sb|someone)', 'him', i) for i in phrase]\n",
    "phrase_her=[re.sub('(sb|someone)', 'her', i) for i in phrase]\n",
    "phrase_them=[re.sub('(sb|someone)', 'them', i) for i in phrase]\n",
    "phrase_me=[re.sub('(sb|someone)', 'me', i) for i in phrase]\n",
    "phrase_you=[re.sub('(sb|someone)','you',i) for i in phrase]\n",
    "phrase_us=[re.sub('(sb|someone)','us',i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24836"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_list=phrase_him+phrase_her+phrase_them+phrase_me+phrase_you+phrase_us+phrase_it+phrase_this+phrase_that+phrase_these+phrase_those\n",
    "phrases_list+=some_cleaned\n",
    "phrases_list=[i for i in phrases_list if len(i.split())!=1]\n",
    "phrases_list=list(set(phrases_list))\n",
    "print(len(phrases_list))\n",
    "phrases_list.append(\"ca n't be bothered\") # we add these two words since they weren't in cambridge dictionary although they are regarded as proper MWE\n",
    "phrases_list.append('up to')\n",
    "len(phrases_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['used to']\n",
      "['used to doing']\n",
      "[\"we 'll see about that\"]\n",
      "['get rid of']\n",
      "['something or other']\n",
      "['something like']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in phrases_list if i==\"used to\"])\n",
    "print([i for i in phrases_list if i==\"used to doing\"])\n",
    "print([i for i in phrases_list if i==\"we 'll see about that\"])\n",
    "print([i for i in phrases_list if i==\"get rid of\"])\n",
    "print([i for i in phrases_list if i==\"something or other\"])\n",
    "print([i for i in phrases_list if i==\"something like\"])\n",
    "#[i for i in phrases_list if re.search(\"wo n't\",i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23778"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in phrases_list if len(i.split())<7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574005475922048"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in phrases_list if len(i.split())<7])/len(phrases_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_list_file=open('phrases_list.txt','w',encoding='utf-8')\n",
    "for i in phrases_list:\n",
    "    phrases_list_file.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code lemmatise phrase_list by using wn.morphy which is a function in wordnet that lemmatise word\n",
    "from nltk.corpus import wordnet as wn\n",
    "original_phrase=[i.split() for i in phrases_list]\n",
    "lemma_phrase=[]\n",
    "for i in original_phrase:\n",
    "    lemma_phrase_sen=[]\n",
    "    for j in i:\n",
    "        lemma_phrase_sen.append(wn.morphy(j))\n",
    "    lemma_phrase.append(lemma_phrase_sen)\n",
    "for i,y in zip(lemma_phrase,original_phrase):\n",
    "    for j,x in enumerate(i):\n",
    "        if x==None:\n",
    "            i[j]=y[j] \n",
    "\n",
    "lemma_phrase_list=[]\n",
    "for i in lemma_phrase:\n",
    "    lemma_phrase_list.append(' '.join(i))\n",
    "\n",
    "# change -ing form\n",
    "#different_bracket=[]\n",
    "#for i,y in zip(lemma_originals,original):\n",
    "    #if i!=y:\n",
    "        #different_bracket.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since wn.morphy function can't handle -ing form, these are processed in a manual way.\n",
    "#and other errors such as 'wa', 'ha','are', 'am' are detected so changed it manually\n",
    "exception=['going', 'something',\n",
    " 'thing',\n",
    " 'anything',\n",
    " 'being',\n",
    " 'nothing',\n",
    " 'everything',\n",
    " 'bring',\n",
    " 'getting',\n",
    " 'coming',\n",
    " 'looking',\n",
    " 'talking',\n",
    " 'morning',\n",
    " 'saying',\n",
    " 'working',\n",
    " 'making',\n",
    " 'thinking',\n",
    " 'taking',\n",
    " 'meeting',\n",
    " 'during',\n",
    " 'telling',\n",
    " 'running',\n",
    " 'feeling',\n",
    " 'building',\n",
    " 'fucking',\n",
    " 'living',\n",
    " 'waiting',\n",
    " 'king',\n",
    " 'using',\n",
    " 'playing',\n",
    " 'leaving',\n",
    " 'asking',\n",
    " 'giving',\n",
    " 'seeing',\n",
    " 'ring',\n",
    " 'calling',\n",
    " 'following',\n",
    " 'evening',\n",
    " 'happening',\n",
    " 'watching',\n",
    " 'wedding',\n",
    " 'sitting',\n",
    " 'lying',\n",
    " 'wearing',\n",
    " 'standing',\n",
    " 'training',\n",
    " 'putting',\n",
    " 'holding',\n",
    " 'starting',\n",
    " 'beginning',\n",
    " 'reading',\n",
    " 'walking',\n",
    " 'killing',\n",
    " 'driving',\n",
    " 'planning',\n",
    " 'fighting',\n",
    " 'keeping',\n",
    " 'darling',\n",
    " 'speaking',\n",
    " 'writing',\n",
    " 'helping',\n",
    " 'eating',\n",
    " 'finding',\n",
    " 'dying',\n",
    " 'hearing',\n",
    " 'listening',\n",
    " 'sing',\n",
    " 'crying',\n",
    " 'sleeping',\n",
    " 'drinking',\n",
    " 'willing',\n",
    " 'meaning',\n",
    " 'knowing',\n",
    " 'growing',\n",
    " 'acting',\n",
    " 'bringing',\n",
    " 'turning',\n",
    " 'screaming',\n",
    " 'opening',\n",
    " 'hanging',\n",
    " 'spring',\n",
    " 'painting',\n",
    " 'flying',\n",
    " 'selling',\n",
    " 'showing',\n",
    " 'leading',\n",
    " 'letting',\n",
    " 'hiding',\n",
    " 'shooting',\n",
    " 'dealing',\n",
    " 'breaking',\n",
    " 'setting',\n",
    " 'learning',\n",
    " 'understanding',\n",
    " 'buying',\n",
    " 'dating',\n",
    " 'heading',\n",
    " 'teaching',\n",
    " 'spending',\n",
    " 'singing',\n",
    " 'warning',\n",
    " 'sending',\n",
    " 'dancing',\n",
    " 'drawing',\n",
    " 'saving',\n",
    " 'winning',\n",
    " 'shopping',\n",
    " 'picking',\n",
    " 'cooking',\n",
    " 'cutting',\n",
    " 'pulling',\n",
    " 'offering',\n",
    " 'swing',\n",
    " 'boring',\n",
    " 'burning',\n",
    " 'passing',\n",
    " 'housing',\n",
    " 'parking',\n",
    " 'wing',\n",
    " 'breathing',\n",
    " 'recording',\n",
    " 'cleaning',\n",
    " 'panting',\n",
    " 'bleeding',\n",
    " 'suffering',\n",
    " 'cheering',\n",
    " 'hunting',\n",
    " 'riding',\n",
    " 'fishing',\n",
    " 'pushing',\n",
    " 'smoking',\n",
    " 'stealing',\n",
    " 'testing',\n",
    " 'closing',\n",
    " 'knocking',\n",
    " 'facing',\n",
    " 'engineering',\n",
    " 'string',\n",
    " 'covering',\n",
    " 'beating',\n",
    " 'yelling',\n",
    " 'landing',\n",
    " 'ending',\n",
    " 'developing',\n",
    " 'hitting',\n",
    " 'rising',\n",
    " 'stopping',\n",
    " 'studying',\n",
    " 'rolling',\n",
    " 'swimming',\n",
    " 'causing',\n",
    " 'serving',\n",
    " 'sharing',\n",
    " 'visiting',\n",
    " 'timing',\n",
    " 'shouting',\n",
    " 'whispering',\n",
    " 'trading',\n",
    " 'sobbing',\n",
    " 'digging',\n",
    " 'smiling',\n",
    " 'guessing',\n",
    " 'seeking',\n",
    " 'wasting',\n",
    " 'feeding',\n",
    " 'joining',\n",
    " 'counting',\n",
    " 'marketing',\n",
    " 'raising',\n",
    " 'racing',\n",
    " 'dressing',\n",
    " 'investigating',\n",
    " 'hurting',\n",
    " 'handling',\n",
    " 'growling',\n",
    " 'cheating',\n",
    " 'kissing',\n",
    " 'pretending',\n",
    " 'bearing',\n",
    " 'annoying',\n",
    " 'touching',\n",
    " 'funding',\n",
    " 'tracking',\n",
    " 'blowing',\n",
    " 'advertising',\n",
    " 'washing',\n",
    " 'firing',\n",
    " 'ringing',\n",
    " 'reaching',\n",
    " 'catching',\n",
    " 'travelling',\n",
    " 'filling',\n",
    " 'crossing',\n",
    " 'thanksgiving',\n",
    " 'kicking',\n",
    " 'ceiling',\n",
    " 'processing',\n",
    " 'coughing',\n",
    " 'arguing',\n",
    " 'worrying',\n",
    " 'entering',\n",
    " 'clothing',\n",
    " 'questioning',\n",
    " 'jumping',\n",
    " 'shaking',\n",
    " 'approaching',\n",
    " 'reporting',\n",
    " 'signing',\n",
    " 'dining',\n",
    " 'begging',\n",
    " 'ruling',\n",
    " 'failing',\n",
    " 'voting',\n",
    " 'fitting',\n",
    " 'starving',\n",
    " 'accounting',\n",
    " 'nursing',\n",
    " 'manufacturing',\n",
    " 'gathering',\n",
    " 'blessing',\n",
    " 'supporting',\n",
    " 'laying',\n",
    " 'climbing',\n",
    " 'outstanding',\n",
    " 'packing',\n",
    " 'floating',\n",
    " 'monitoring',\n",
    " 'judging',\n",
    " 'lightning',\n",
    " 'freezing',\n",
    " 'caring',\n",
    " 'sting',\n",
    " 'finishing',\n",
    " 'pressing',\n",
    " 'gambling',\n",
    " 'performing',\n",
    " 'dreaming',\n",
    " 'kidnapping',\n",
    " 'believing',\n",
    " 'collecting',\n",
    " 'traveling',\n",
    " 'healing',\n",
    " 'pudding',\n",
    " 'attending',\n",
    " 'backing',\n",
    " 'lighting',\"wa\",\"are\",\"ha\",\"am\"]\n",
    "\n",
    "def correction(text):\n",
    "    if text in exception:\n",
    "        text=re.sub('going','go',text)\n",
    "        text=re.sub('getting','get',text)\n",
    "        text=re.sub('coming','come',text)\n",
    "        text=re.sub('looking','look',text)\n",
    "        text=re.sub('talking','talk',text)\n",
    "        text=re.sub('saying','say',text)\n",
    "        text=re.sub('working','work',text)\n",
    "        text=re.sub('making','make',text)\n",
    "        text=re.sub('thinking','think',text)\n",
    "        text=re.sub('taking','take',text)\n",
    "        text=re.sub('meeting','meet',text)\n",
    "        text=re.sub('telling','tell',text)\n",
    "        text=re.sub('running','run',text)\n",
    "        text=re.sub('feeling','feel',text)\n",
    "        text=re.sub('fucking','fuck',text)\n",
    "        text=re.sub('living','live',text)\n",
    "        text=re.sub('waiting','wait',text)\n",
    "        text=re.sub('using','use',text)\n",
    "        text=re.sub('playing','play',text)\n",
    "        text=re.sub('leaving','leave',text)\n",
    "        text=re.sub('asking','ask',text)\n",
    "        text=re.sub('giving','give',text)\n",
    "        text=re.sub('seeing','see',text)\n",
    "        text=re.sub('calling','call',text)\n",
    "        text=re.sub('following','follow',text)\n",
    "        text=re.sub('happening','happen',text)\n",
    "        text=re.sub('watching','watch',text)\n",
    "        text=re.sub('sitting','sit',text)\n",
    "        text=re.sub('lying','lie',text)\n",
    "        text=re.sub('wearing','wear',text)\n",
    "        text=re.sub('standing','stand',text)\n",
    "        text=re.sub('training','train',text)\n",
    "        text=re.sub('putting','put',text)\n",
    "        text=re.sub('holding','hold',text)\n",
    "        text=re.sub('starting','start',text)\n",
    "        text=re.sub('beginning','begin',text)\n",
    "        text=re.sub('reading','read',text)\n",
    "        text=re.sub('walking','walk',text)\n",
    "        text=re.sub('killing','kill',text)\n",
    "        text=re.sub('driving','drive',text)\n",
    "        text=re.sub('planning','plan',text)\n",
    "        text=re.sub('fighting','fight',text)\n",
    "        text=re.sub('keeping','keep',text)\n",
    "        text=re.sub('speaking','speak',text)\n",
    "        text=re.sub('writing','write',text)\n",
    "        text=re.sub('helping','help',text)\n",
    "        text=re.sub('eating','eat',text)\n",
    "        text=re.sub('finding','find',text)\n",
    "        text=re.sub('dying','die',text)\n",
    "        text=re.sub('hearing','hear',text)\n",
    "        text=re.sub('listening','listen',text)\n",
    "        text=re.sub('crying','cry',text)\n",
    "        text=re.sub('sleeping','sleep',text)\n",
    "        text=re.sub('drinking', 'drink', text)\n",
    "        text=re.sub('meaning', 'mean', text)\n",
    "        text=re.sub('knowing','know',text)\n",
    "        text=re.sub('growing','grow',text)\n",
    "        text=re.sub('acting','act',text)\n",
    "        text=re.sub('bringing','bring',text)\n",
    "        text=re.sub('turning','turn',text)\n",
    "        text=re.sub('screaming','scream',text)\n",
    "        text=re.sub('opening','open',text)\n",
    "        text=re.sub('hanging', 'hang',text)\n",
    "        text=re.sub('painting', 'paint',text)\n",
    "        text=re.sub('flying', 'fly',text)\n",
    "        text=re.sub('selling', 'sell',text)\n",
    "        text=re.sub('showing', 'show',text)\n",
    "        text=re.sub('leading', 'lead',text)\n",
    "        text=re.sub('letting', 'let',text)\n",
    "        text=re.sub('hiding', 'hide',text)\n",
    "        text=re.sub('shooting', 'shoot',text)\n",
    "        text=re.sub('dealing', 'deal',text)\n",
    "        text=re.sub('breaking','break',text)\n",
    "        text=re.sub('setting', 'set',text)\n",
    "        text=re.sub('learning', 'learn',text)\n",
    "        text=re.sub('understanding', 'understand',text)\n",
    "        text=re.sub('buying','buy',text)\n",
    "        text=re.sub('dating', 'date',text)\n",
    "        text=re.sub('heading', 'head',text)\n",
    "        text=re.sub('teaching', 'teach',text)\n",
    "        text=re.sub('spending', 'spend',text)\n",
    "        text=re.sub('singing', 'sing',text)\n",
    "        text=re.sub('warning', 'warn',text)\n",
    "        text=re.sub('sending', 'send',text)\n",
    "        text=re.sub('dancing', 'dance',text)\n",
    "        text=re.sub('drawing', 'draw',text)\n",
    "        text=re.sub('saving', 'save',text)\n",
    "        text=re.sub('winning', 'win',text)\n",
    "        text=re.sub('shopping', 'shop',text)\n",
    "        text=re.sub('picking', 'pick',text)\n",
    "        text=re.sub('cooking', 'cook',text)\n",
    "        text=re.sub('cutting', 'cut',text)\n",
    "        text=re.sub('pulling', 'pull',text)\n",
    "        text=re.sub('offering', 'offer',text)\n",
    "    #text=re.sub('boring', 'bore', text)\n",
    "        text=re.sub('burning', 'burn',text)\n",
    "        text=re.sub('passing', 'pass',text)\n",
    "        text=re.sub('housing', 'house',text)\n",
    "        text=re.sub('parking', 'park',text)\n",
    "        text=re.sub('breathing', 'breathe',text)\n",
    "        text=re.sub('recording', 'record',text)\n",
    "        text=re.sub('cleaning', 'clean',text)\n",
    "        text=re.sub('panting', 'pant',text)\n",
    "        text=re.sub('bleeding', 'bleed',text)\n",
    "        text=re.sub('suffering', 'suffer',text)\n",
    "        text=re.sub('cheering', 'cheer',text)\n",
    "        text=re.sub('hunting', 'hunt',text)\n",
    "        text=re.sub('riding', 'ride',text)\n",
    "    # fishing->fish\n",
    "        text=re.sub('pushing', 'push',text)\n",
    "        text=re.sub('smoking', 'smoke',text)\n",
    "        text=re.sub('stealing', 'steal',text)\n",
    "        text=re.sub('testing', 'test',text)\n",
    "        text=re.sub('closing', 'close',text)\n",
    "        text=re.sub('knocking', 'knock',text)\n",
    "        text=re.sub('facing', 'face',text)\n",
    "    #text=re.sub('engineering', 'engineer',text)\n",
    "        text=re.sub('covering', 'cover',text)\n",
    "        text=re.sub('beating', 'beat',text)\n",
    "        text=re.sub('yelling', 'yell',text)\n",
    "    #text=re.sub('landing', 'land',text)\n",
    "        text=re.sub('ending', 'end',text)\n",
    "        text=re.sub('developing', 'develop',text)\n",
    "        text=re.sub('hitting', 'hit',text)\n",
    "        text=re.sub('rising', 'rise',text)\n",
    "        text=re.sub('stopping', 'stop',text)\n",
    "        text=re.sub('studying', 'study',text)\n",
    "        text=re.sub('rolling', 'roll',text)\n",
    "        text=re.sub('swimming', 'swim',text)\n",
    "        text=re.sub('causing', 'cause',text)\n",
    "        text=re.sub('serving', 'serve',text)\n",
    "        text=re.sub('sharing', 'share',text)\n",
    "        text=re.sub('visiting', 'visit',text)\n",
    "        text=re.sub('shouting', 'shout',text)\n",
    "        text=re.sub('whispering', 'whisper',text)\n",
    "        text=re.sub('trading', 'trade',text)\n",
    "        text=re.sub('sobbing', 'sob',text)\n",
    "        text=re.sub('digging', 'dig',text)\n",
    "        text=re.sub('smiling', 'smile',text)\n",
    "        text=re.sub('guessing', 'guess',text)\n",
    "        text=re.sub('seeking', 'seek',text)\n",
    "    #timing->time\n",
    "        text=re.sub('wasting', 'waste', text)\n",
    "        text=re.sub('feeding', 'feed', text)\n",
    "        text=re.sub('joining', 'join',text)\n",
    "        text=re.sub('counting', 'count',text)\n",
    "        text=re.sub('marketing', 'market',text)\n",
    "        text=re.sub('raising', 'raise',text)\n",
    "        text=re.sub('racing', 'race',text)\n",
    "        text=re.sub('dressing', 'dress',text)\n",
    "        text=re.sub('investigating', 'investigate',text)\n",
    "        text=re.sub('hurting','hurt',text)\n",
    "        text=re.sub('handling', 'handle',text)\n",
    "        text=re.sub('growling', 'growl',text)\n",
    "        text=re.sub('cheating', 'cheat',text)\n",
    "        text=re.sub('kissing', 'kiss',text)\n",
    "        text=re.sub('pretending','pretend',text)\n",
    "        text=re.sub('bearing', 'bear',text)\n",
    "        text=re.sub('annoying','annoy',text)\n",
    "        text=re.sub('touching', 'touch',text)\n",
    "        text=re.sub('funding', 'fund',text)\n",
    "        text=re.sub('tracking', 'track',text)\n",
    "        text=re.sub('blowing', 'blow',text)\n",
    "        text=re.sub('advertising','advertise',text)\n",
    "        text=re.sub('washing','wash',text)\n",
    "        text=re.sub('firing', 'fire',text)\n",
    "        text=re.sub('ringing', 'ring',text)\n",
    "        text=re.sub('reaching', 'reach',text)\n",
    "        text=re.sub('catching', 'catch',text)\n",
    "        text=re.sub('travelling', 'travel',text)\n",
    "        text=re.sub('filling', 'fill',text)\n",
    "        text=re.sub('crossing', 'cross',text)\n",
    "        text=re.sub('kicking', 'kick',text)\n",
    "        text=re.sub('processing', 'process',text)\n",
    "        text=re.sub('coughing', 'cough',text)\n",
    "        text=re.sub('arguing', 'argue',text)\n",
    "        text=re.sub('worrying', 'worry',text)\n",
    "        text=re.sub('entering', 'enter',text)\n",
    "     #clothing->clothe\n",
    "        text=re.sub('questioning', 'question',text)\n",
    "        text=re.sub('jumping', 'jump',text)\n",
    "        text=re.sub('shaking', 'shake',text)\n",
    "        text=re.sub('approaching', 'approach',text)\n",
    "        text=re.sub('reporting', 'report',text)\n",
    "        text=re.sub('signing','sign',text)\n",
    "        text=re.sub('dining','dine',text)\n",
    "        text=re.sub('begging', 'beg',text)\n",
    "        text=re.sub('ruling', 'rule',text)\n",
    "        text=re.sub('failing', 'fail',text)\n",
    "        text=re.sub('voting', 'vote',text)\n",
    "        text=re.sub('fitting', 'fit',text)\n",
    "        text=re.sub('starving', 'starve',text)\n",
    "    #accounting->account\n",
    "        text=re.sub('nursing','nurse',text)\n",
    "        text=re.sub('manufacturing', 'manufacture',text)\n",
    "        text=re.sub('gathering', 'gather',text)\n",
    "        text=re.sub('blessing', 'bless',text)\n",
    "        text=re.sub('supporting','support',text)\n",
    "        text=re.sub('laying', 'lay',text)\n",
    "        text=re.sub('climbing','climb',text)\n",
    "        text=re.sub('packing', 'pack',text)\n",
    "        text=re.sub('floating', 'float',text)\n",
    "        text=re.sub('monitoring', 'monitor',text)\n",
    "        text=re.sub('judging', 'judge',text)\n",
    "        text=re.sub('freezing', 'freeze',text)\n",
    "        text=re.sub('caring', 'care',text)\n",
    "        text=re.sub('finishing', 'finish',text)\n",
    "        text=re.sub('pressing', 'press',text)\n",
    "        text=re.sub('gambling', 'gamble',text)\n",
    "        text=re.sub('performing', 'perform',text)\n",
    "        text=re.sub('dreaming', 'dream',text)\n",
    "        text=re.sub('kidnapping', 'kidnap',text)\n",
    "        text=re.sub('believing', 'believe',text)\n",
    "        text=re.sub('collecting', 'collect',text)\n",
    "        text=re.sub('traveling', 'travel',text)\n",
    "        text=re.sub('healing', 'heal',text)\n",
    "        text=re.sub('attending', 'attend',text)\n",
    "        text = re.sub(\"am\",\"be\",text)\n",
    "        text = re.sub(\"wa\",\"be\",text)\n",
    "        text = re.sub(\"are\",\"be\",text)\n",
    "        text = re.sub(\"ha\",\"have\",text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "corrected_phrases=[]\n",
    "for i in lemma_phrase_list:\n",
    "    corrected_phrase=[]\n",
    "    for j in i.split():\n",
    "        corrected_phrase.append(correction(j))\n",
    "    corrected_phrases.append(corrected_phrase)\n",
    "    \n",
    "corrected_phrases_list=[' '.join(i) for i in corrected_phrases]\n",
    "\n",
    "        \n",
    "#corrected_phrase_2=[correction2(i) for i in corrected_phrase_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_phrases_list_file=open('lemma_phrases_list.txt','w',encoding='utf-8')\n",
    "for i in corrected_phrases_list:\n",
    "    lemma_phrases_list_file.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24836"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_phrases_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
