{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11567"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=open('C:/Users/gartl/jupyter_mycode/data folder/cambridge_phrase.txt',encoding='utf-8').readlines() #put your address\n",
    "phrase=[i.strip().lower() for i in phrase]\n",
    "phrase=[re.sub(\"[\\#@;?:<>.!{}`+=~|]\",'',i) for i in phrase]\n",
    "phrase=list(set(phrase))\n",
    "len(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"what's up\"]\n",
      "['what’s eating someone']\n",
      "[\"it'll cost you\"]\n",
      "['something like']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in phrase if i==\"what's up\"])\n",
    "print([i for i in phrase if i==\"what’s eating someone\"])\n",
    "print([i for i in phrase if i==\"it'll cost you\"])\n",
    "print([i for i in phrase if i=='something like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=[re.sub('’',\"'\",i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"won't take no for an answer\"]\n",
      "[]\n",
      "11567\n"
     ]
    }
   ],
   "source": [
    "[i for i in phrase if re.search(\"sb's\", i)]\n",
    "phrase.remove(\"will never hear the end of it\")\n",
    "phrase.remove(\"will not take no for an answer\")\n",
    "phrase.append(\"'ll never hear the end of it\")\n",
    "phrase.append(\"won't take no for an answer\")\n",
    "print([i for i in phrase if i==\"won't take no for an answer\"])\n",
    "print([i for i in phrase if i.startswith('are')])\n",
    "print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process common contractions as two words. in this case what's == what 's, we'll == we 'll etc..\n",
    "#almost every corpus, these words are stored in this way because every contractions has a bit different meaning from original version\n",
    "def space_place(cleaned):\n",
    "    cleaned = re.sub(\"what's\",\"what 's\",cleaned)\n",
    "    cleaned = re.sub(\"how's\",\"how 's\",cleaned)\n",
    "    cleaned = re.sub(\"why's\",\"why 's\",cleaned)\n",
    "    cleaned = re.sub(\"where's\",\"where 's\",cleaned)\n",
    "    cleaned = re.sub(\"when's\",\"when 's\",cleaned)\n",
    "    cleaned = re.sub(\"who's\",\"who 's\",cleaned)\n",
    "    cleaned = re.sub(\"it's\",\"it 's\",cleaned)\n",
    "    cleaned = re.sub(\"sth's\", \"sth 's\",cleaned)\n",
    "    cleaned = re.sub(\"isn't\",\"is n't\",cleaned)\n",
    "    cleaned = re.sub(\"aren't\",\"are n't\",cleaned)\n",
    "    cleaned = re.sub(\"wasn't\",\"was n't\",cleaned)\n",
    "    cleaned = re.sub(\"weren't\",\"were n't\",cleaned)\n",
    "    cleaned = re.sub(\"can't\", \"ca n't\",cleaned)\n",
    "    cleaned = re.sub(\"couldn't\",\"could n't\",cleaned)\n",
    "    cleaned = re.sub(\"shouldn't\",\"should n't\",cleaned)\n",
    "    cleaned = re.sub(\"won't\", \"wo n't\",cleaned)\n",
    "    cleaned = re.sub(\"wouldn't\", \"would n't\",cleaned)\n",
    "    cleaned = re.sub(\"don't\", \"do n't\",cleaned)\n",
    "    cleaned = re.sub(\"doesn't\", \"does n't\",cleaned)\n",
    "    cleaned = re.sub(\"didn't\", \"did n't\",cleaned)\n",
    "    cleaned = re.sub(\"mustn't\", \"must n't\",cleaned)\n",
    "    cleaned = re.sub(\"hasn't\", \"has n't\",cleaned)\n",
    "    cleaned = re.sub(\"haven't\", \"have n't\",cleaned)\n",
    "    cleaned = re.sub(\"hadn't\", \"had n't\",cleaned)\n",
    "    cleaned = re.sub(\"it'll\", \"it 'll\",cleaned)\n",
    "    cleaned = re.sub(\"we'll\", \"we 'll\",cleaned)\n",
    "    cleaned = re.sub(\"they'll\", \"they 'll\",cleaned)\n",
    "    cleaned = re.sub(\"that'll\", \"that 'll\",cleaned)\n",
    "    cleaned = re.sub(\"there'll\", \"there 'll\",cleaned)\n",
    "    cleaned = re.sub(\"i'll\", \"i 'll\",cleaned)\n",
    "    cleaned = re.sub(\"you're\", \"you 're\",cleaned)\n",
    "    cleaned = re.sub(\"they're\", \"they 're\",cleaned)\n",
    "    cleaned = re.sub(\"i've\", \"i 've\",cleaned)\n",
    "    cleaned = re.sub(\"you've\", \"you 've\",cleaned)\n",
    "    \n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=[space_place(i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"what 's eating someone\"]\n",
      "[\"i/we 'll (have to) see\", \"we 'll (soon) see about that\", \"i 'll/we 'll cross that bridge when i/we come/get to it\"]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in phrase if i==\"what 's eating someone\"])\n",
    "print([i for i in phrase if re.search(\"we 'll\", i)])\n",
    "print([i for i in phrase if re.search(\"sth's\", i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029\n"
     ]
    }
   ],
   "source": [
    "print(len(set([i for i in phrase if re.search('\\(',i)!=None]))) #the number of phrases that include bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find phrases that have a bracket (or brackets) and eliminate the words inside the bracket\n",
    "def bracket(x):\n",
    "    bracket_list=[]\n",
    "    if re.search('\\(',x)!=None: #find phrases that include bracket\n",
    "        string=x.split()\n",
    "        bracket=[]\n",
    "        for i in string:\n",
    "            if re.search('\\(',i)==None and re.search('\\)',i)==None: #extract words which are outside bracket. ex. finish (sth) up => finish up                                                            \n",
    "                bracket.append(i)\n",
    "        text=' '.join(bracket)\n",
    "        bracket_list.append(text)\n",
    "    return bracket_list\n",
    "                \n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make a face', 'sober up', 'fade out', 'put sb off', 'push sth', 'bite back', \"what 's that about\", 'make a difference', 'word is', 'take something in stride', 'have your heart set on something', 'at the helm', \"it 's no use\", 'stiff/straight as a ramrod', 'man to man', 'the games people play', 'fog up', 'shiver down your spine', 'shift ground', 'leave off']\n"
     ]
    }
   ],
   "source": [
    "bracket=[bracket(i) for i in phrase]\n",
    "bracket=[i for i in bracket if len(i)>0] #eliminate empty list\n",
    "bracket=[j for i in bracket for j in i] #2d list -> 1d list\n",
    "bracket=[i for i in bracket if len(i.split())>1]# eliminate one word results since these are not meet our notion of MWE \n",
    "print(bracket[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11567\n",
      "11567\n",
      "11566\n",
      "920\n",
      "12306\n"
     ]
    }
   ],
   "source": [
    "print(len(phrase))\n",
    "phrase=[re.sub(\"[()]\",'',i) for i in phrase]\n",
    "print(len(phrase))\n",
    "print(len(set(phrase)))\n",
    "print(len(set(bracket)))#the number of phrases that eliminate a bracket:920, the number of phrases that contain a bracket:1029\n",
    "phrase=list(set(phrase+bracket))\n",
    "print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find phrases that have a slash (or slashes) and split it by slash to make every possible phrases\n",
    "def slash(x):\n",
    "    #slashes=[]\n",
    "    slash_list=[]\n",
    "    if re.search('/',x)!=None: #find phrases that include slash\n",
    "        string=x.split()\n",
    "        for i,x in enumerate(string):\n",
    "            if re.search('/',x)!=None:#find the wordstring that include slash in phrase \n",
    "                slash=x.split('/') #split it by slash\n",
    "                #print(slash)\n",
    "                for w in slash: #make separate headword, ex) push sth up/down => push sth up, push sth down\n",
    "                    string[i]=w \n",
    "                    #print(string[i])\n",
    "                    text=' '.join(string)\n",
    "                    slash_list.append(text)\n",
    "                    #print(text)\n",
    "    return slash_list\n",
    "                    \n",
    "slashed=[slash(i) for i in phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3924\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "slashed=[slash(i) for i in phrase] #find phrases include slash\n",
    "slashed=[i for i in slashed if len(i)>0] #eliminate blank lists\n",
    "slashed=[j for i in slashed for j in i] # make 2d nested list into 1d list\n",
    "anti_slashed=[i for i in slashed if re.search('/',i)!=None] #phrases that include two or more slashes\n",
    "slashed=[i for i in slashed if re.search('/',i)==None]\n",
    "anti_slashed=list(set(anti_slashed))\n",
    "slashed=list(set(slashed))\n",
    "print(len(slashed))\n",
    "print(len(anti_slashed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slash(x):\n",
    "    #slashes=[]\n",
    "    slash_list=[]\n",
    "    if re.search('/',x)!=None: #find phrases that include slash\n",
    "        string=x.split()\n",
    "        for i,x in enumerate(string):\n",
    "            if re.search('/',x)!=None:#find the wordstring that include slash in phrase \n",
    "                slash=x.split('/') #split it by slash\n",
    "                #print(slash)\n",
    "                for w in slash: #make separate headword, ex) push sth up/down => push sth up, push sth down\n",
    "                    string[i]=w \n",
    "                    #print(string[i])\n",
    "                    text=' '.join(string)\n",
    "                    slash_list.append(text)\n",
    "                    #print(text)\n",
    "    return slash_list\n",
    "                    \n",
    "anti_slashed_1=[slash(i) for i in anti_slashed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "anti_slashed_1=[slash(i) for i in anti_slashed]\n",
    "anti_slashed_1=[i for i in anti_slashed_1 if len(i)>0] #eliminate blank lists\n",
    "anti_slashed_1=[j for i in anti_slashed_1 for j in i]\n",
    "anti_anti_slashed_1=[i for i in anti_slashed_1 if re.search('/',i)!=None] #phrases that include two or more slashes\n",
    "slashed_1=[i for i in anti_slashed_1 if re.search('/',i)==None]\n",
    "anti_anti_slashed_1=list(set(anti_anti_slashed_1))\n",
    "slashed_1=list(set(slashed_1))\n",
    "print(len(slashed_1))\n",
    "print(len(anti_anti_slashed_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slash(x):\n",
    "    #slashes=[]\n",
    "    slash_list=[]\n",
    "    if re.search('/',x)!=None: #find phrases that include slash\n",
    "        string=x.split()\n",
    "        for i,x in enumerate(string):\n",
    "            if re.search('/',x)!=None:#find the wordstring that include slash in phrase \n",
    "                slash=x.split('/') #split it by slash\n",
    "                #print(slash)\n",
    "                for w in slash: #make separate headword, ex) push sth up/down => push sth up, push sth down\n",
    "                    string[i]=w \n",
    "                    #print(string[i])\n",
    "                    text=' '.join(string)\n",
    "                    slash_list.append(text)\n",
    "                    #print(text)\n",
    "    return slash_list\n",
    "                    \n",
    "anti_slashed_2=[slash(i) for i in anti_anti_slashed_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "anti_slashed_2=[slash(i) for i in anti_anti_slashed_1]\n",
    "anti_slashed_2=[i for i in anti_slashed_2 if len(i)>0] #eliminate blank lists\n",
    "anti_slashed_2=[j for i in anti_slashed_2 for j in i]\n",
    "slashed_2=[i for i in anti_slashed_2 if re.search('/',i)==None]\n",
    "slashed_2=list(set(slashed_2))\n",
    "print(len(slashed_2))\n",
    "print(len([i for i in anti_slashed_2 if re.search('/',i)!=None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12306\n",
      "1946\n",
      "10360\n",
      "14115\n"
     ]
    }
   ],
   "source": [
    "print(len(phrase))\n",
    "print(len([i for i in phrase if re.search('/',i)!=None]))\n",
    "phrase=[i for i in phrase if re.search('/',i)==None]\n",
    "print(len(phrase))\n",
    "phrase=list(set(phrase+slashed+slashed_1+slashed_2))\n",
    "print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thumb your nose at something', 'smooth over something', 'back onto sth', 'have your fair share of sth', 'point towards sth', 'spread something out over something', 'make off with something', 'turn sth to sth', 'live with something', 'lumber sb with sth']\n",
      "['creep over sb', 'do wonders for someone', 'make an honest woman out of sb', 'prey on someone', 'throw together someone', 'fob off someone', 'reflect on someone', 'focus on sb', 'hold on to sb', 'all eyes are on sb']\n",
      "2746\n",
      "1223\n",
      "4\n",
      "5\n",
      "3\n",
      "['something goes for something else', 'something else', 'no sooner does something happen than something else happens', 'something goes for someone else']\n",
      "['something like 96 percent, half, etc', 'treat someone like dirt', 'something like', 'know something like the back of your hand', 'or something like that']\n"
     ]
    }
   ],
   "source": [
    "# this code find headwords that last word is sth/something and sb/somebody and eliminate sth/something and sb/somebody\n",
    "#It's because objective pronoun that comes to the end of the phrase in headword typically not considered as a part of MWEs. \n",
    "sth_end=[i for i in phrase if i.endswith('sth') or i.endswith('something')]   \n",
    "print(sth_end[:10])\n",
    "\n",
    "sb_end=[i for i in phrase if i.endswith('sb') or i.endswith('someone')]\n",
    "print(sb_end[:10])\n",
    "\n",
    "\n",
    "sth_start=['something to go','something or other','something for nothing']\n",
    "sth_sb_else=[i for i in phrase if re.search('(something else|someone else)',i)]\n",
    "sth_sb_like=[i for i in phrase if re.search('(something like|someone like)',i)]\n",
    "\n",
    "print(len(sth_end))\n",
    "print(len(sb_end))\n",
    "print(len(sth_sb_else))\n",
    "print(len(sth_sb_like))\n",
    "print(len(sth_start))\n",
    "print(sth_sb_else)\n",
    "print(sth_sb_like)\n",
    "\n",
    "some=sth_end+sb_end+sth_sb_else+sth_sb_like+sth_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10134\n",
      "3969\n",
      "14106\n"
     ]
    }
   ],
   "source": [
    "#eliminate sth and sb if it is a last word\n",
    "phrase=[i for i in phrase if i not in some]\n",
    "print(len(phrase))\n",
    "sth_end=[' '.join(i.split()[:-1]) for i in sth_end]\n",
    "sb_end=[' '.join(i.split()[:-1]) for i in sb_end]\n",
    "some_cleaned=sth_end+sb_end\n",
    "print(len(some_cleaned))\n",
    "phrase+=some_cleaned\n",
    "#exceptions: something to go-> to go\n",
    "phrase.append('to go')\n",
    "#exceptions: someone and something in this case used as sb and sth. can be seen in headwords only\n",
    "phrase.append('treat someone like dirt')\n",
    "phrase.append('know something like the back of your hand')\n",
    "print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sb and sth into certain objective pronoun \n",
    "#Since acronyms such as sth and sb (or something and somebody)in objective pronoun position cannot be found in real text\n",
    "#therefore to detect MWEs precisely, they should be changed into objective pronouns.\n",
    "\n",
    "phrase_it=[re.sub('(sth|something)','it',i) for i in phrase if re.search(\"(sth|something)\",i)!=None]\n",
    "phrase_this=[re.sub('(sth|something)','this',i) for i in phrase if re.search(\"(sth|something)\",i)!=None]\n",
    "phrase_that=[re.sub('(sth|something)','that',i) for i in phrase if re.search(\"(sth|something)\",i)!=None]\n",
    "phrase_these=[re.sub('(sth|something)','these',i) for i in phrase if re.search(\"(sth|something)\",i)!=None]\n",
    "phrase_those=[re.sub('(sth|something)','those',i) for i in phrase if re.search(\"(sth|something)\",i)!=None]\n",
    "phrase_him=[re.sub('(sb|someone)', 'him', i) for i in phrase if re.search(\"(sb|someone)\",i)!=None and re.search(\"(sb's|someone's)\",i)==None]\n",
    "phrase_her=[re.sub(\"(sb|someone|sb's|someone's)\", 'her', i) for i in phrase if re.search(\"(sb|someone|sb's|someone's)\",i)!=None]\n",
    "phrase_them=[re.sub('(sb|someone)', 'them', i) for i in phrase if re.search(\"(sb|someone)\",i)!=None and re.search(\"(sb's|someone's)\",i)==None]\n",
    "phrase_me=[re.sub('(sb|someone)', 'me', i) for i in phrase if re.search(\"(sb|someone)\",i)!=None and re.search(\"(sb's|someone's)\",i)==None]\n",
    "phrase_you=[re.sub('(sb|someone)','you',i) for i in phrase if re.search(\"(sb|someone)\",i)!=None and re.search(\"(sb's|someone's)\",i)==None]\n",
    "phrase_us=[re.sub('(sb|someone)','us',i) for i in phrase if re.search(\"(sb|someone)\",i)!=None and re.search(\"(sb's|someone's)\",i)==None]\n",
    "phrase_his=[re.sub(\"(sb's|someone's)\", 'his', i) for i in phrase if re.search(\"(sb's|someone's)\",i)!=None]\n",
    "phrase_their=[re.sub(\"(sb's|someone's)\", 'their', i) for i in phrase if re.search(\"(sb's|someone's)\",i)!=None]\n",
    "phrase_my=[re.sub(\"(sb's|someone's)\", 'my', i) for i in phrase if re.search(\"(sb's|someone's)\",i)!=None]\n",
    "phrase_your=[re.sub(\"(sb's|someone's)\",'your',i) for i in phrase if re.search(\"(sb's|someone's)\",i)!=None]\n",
    "phrase_our=[re.sub(\"(sb's|someone's)\",'our',i) for i in phrase if re.search(\"(sb's|someone's)\",i)!=None]\n",
    "pure_phrase=[i for i in phrase if re.search(\"(sth|sb|sb's)\",i)==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25578\n"
     ]
    }
   ],
   "source": [
    "MWE_list=phrase_him+phrase_her+phrase_them+phrase_me+phrase_you+phrase_us+phrase_it+phrase_this+phrase_that+phrase_these+phrase_those+phrase_his+phrase_their+phrase_my+phrase_your+phrase_our+pure_phrase\n",
    "MWE_list=[i for i in MWE_list if len(i.split())!=1]\n",
    "MWE_list=list(set(MWE_list))\n",
    "print(len(MWE_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some MWEs have two acronyms (sth, sb, sb's) and since re.sub only replace one word each time, same process should be done one more time \n",
    "phrase_it_1=[re.sub('sth','it',i) for i in MWE_list if re.search(\"sth\",i)!=None]\n",
    "phrase_this_1=[re.sub('sth','this',i) for i in MWE_list if re.search(\"sth\",i)!=None]\n",
    "phrase_that_1=[re.sub('sth','that',i) for i in MWE_list if re.search(\"sth\",i)!=None]\n",
    "phrase_these_1=[re.sub('sth','these',i) for i in MWE_list if re.search(\"sth\",i)!=None]\n",
    "phrase_those_1=[re.sub('sth','those',i) for i in MWE_list if re.search(\"sth\",i)!=None]\n",
    "phrase_him_1=[re.sub('sb', 'him', i) for i in MWE_list if re.search(\"sb\",i)!=None and re.search(\"sb's\",i)==None]\n",
    "phrase_her_1=[re.sub(\"(sb|sb's)\", 'her', i) for i in MWE_list if re.search(\"(sb|sb's)\",i)!=None]\n",
    "phrase_them_1=[re.sub('sb', 'them', i) for i in MWE_list if re.search(\"sb\",i)!=None and re.search(\"sb's\",i)==None]\n",
    "phrase_me_1=[re.sub('sb', 'me', i) for i in MWE_list if re.search(\"sb\",i)!=None and re.search(\"sb's\",i)==None]\n",
    "phrase_you_1=[re.sub('sb','you',i) for i in MWE_list if re.search(\"sb\",i)!=None and re.search(\"sb's\",i)==None]\n",
    "phrase_us_1=[re.sub('sb','us',i) for i in MWE_list if re.search(\"sb\",i)!=None and re.search(\"sb's\",i)==None]\n",
    "phrase_his_1=[re.sub(\"sb's\", 'his', i) for i in MWE_list if re.search(\"sb's\",i)!=None]\n",
    "phrase_their_1=[re.sub(\"(sb's|someone's)\", 'their', i) for i in MWE_list if re.search(\"sb's\",i)!=None]\n",
    "phrase_my_1=[re.sub(\"(sb's|someone's)\", 'my', i) for i in MWE_list if re.search(\"sb's\",i)!=None]\n",
    "phrase_your_1=[re.sub(\"(sb's|someone's)\",'your',i) for i in MWE_list if re.search(\"sb's\",i)!=None]\n",
    "phrase_our_1=[re.sub(\"(sb's|someone's)\",'our',i) for i in MWE_list if re.search(\"sb's\",i)!=None]\n",
    "pure_phrases_list=[i for i in MWE_list if re.search(\"(sth|sb|sb's)\",i)==None]\n",
    "additional_phrases_list=phrase_him_1+phrase_her_1+phrase_them_1+phrase_me_1+phrase_you_1+phrase_us_1+phrase_it_1+phrase_this_1+phrase_that_1+phrase_these_1+phrase_those_1+phrase_his_1+phrase_their_1+phrase_my_1+phrase_your_1+phrase_our_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MWES that are recognized to include something as a word added to the MWE list\n",
    "MWE_list=pure_phrases_list+additional_phrases_list\n",
    "MWE_list=list(set(MWE_list))\n",
    "MWE_list.append('something or other')\n",
    "MWE_list.append('something for nothing')\n",
    "MWE_list.append('something else')\n",
    "MWE_list.append('or something like that')\n",
    "MWE_list.append('something like')\n",
    "# we add these two words since they weren't in cambridge dictionary although they regarded as proper MWE\n",
    "MWE_list.append(\"ca n't be bothered\") \n",
    "MWE_list.append('up to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['used to']\n",
      "['used to doing']\n",
      "[\"we 'll see about that\"]\n",
      "['get rid of']\n",
      "['something or other']\n",
      "['something like']\n",
      "['something else']\n",
      "['in all truthfulness']\n",
      "26134\n"
     ]
    }
   ],
   "source": [
    "#check phrases list have proper phrases\n",
    "print([i for i in MWE_list if i==\"used to\"])\n",
    "print([i for i in MWE_list if i==\"used to doing\"])\n",
    "print([i for i in MWE_list if i==\"we 'll see about that\"])\n",
    "print([i for i in MWE_list if i==\"get rid of\"])\n",
    "print([i for i in MWE_list if i==\"something or other\"])\n",
    "print([i for i in MWE_list if i==\"something like\"])\n",
    "print([i for i in MWE_list if i==\"something else\"])\n",
    "print([i for i in MWE_list if i==\"in all truthfulness\"])\n",
    "\n",
    "#the number of phrases that phrases list contain: 26134\n",
    "print(len(MWE_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#final check that phrases in phrases list\n",
    "pl_sth=[i for i in MWE_list if re.search(\"sth\",i)]\n",
    "pl_sb=[i for i in MWE_list if re.search(\"sb\",i)]\n",
    "pl_sbs=[i for i in MWE_list if re.search(\"sb's\",i)]\n",
    "pl=pl_sth+pl_sb+pl_sbs\n",
    "print(len(pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate phrases that include etc \n",
    "#because several words that have comma sign in front of etc can't be used together. \n",
    "#should select only one of them(e.g. repay our effort, time, attention, etc ) \n",
    "length, ret = 0, []\n",
    "\n",
    "for mwe in MWE_list:\n",
    "  # initialize\n",
    "    front, back, ck, process = \"\", \"\", 0 , []\n",
    "\n",
    "  # find MWEs that contain etc and count the number\n",
    "    if \"etc\" in mwe.split():\n",
    "        length+=1\n",
    "\n",
    "    for word in mwe.split():\n",
    "      # if MWE contain comma or the word 'etc', it will split MWE by comma and eliminate 'etc'\n",
    "        if ',' in word: \n",
    "            process.append(word[:-1])\n",
    "            continue\n",
    "        if word == \"etc\": \n",
    "            ck = 1\n",
    "            continue\n",
    "\n",
    "      # MWEs that are not applied to those cases, remain same \n",
    "        if ck==0: \n",
    "            if front == \"\": \n",
    "                front = word\n",
    "            \n",
    "            else: \n",
    "                front = front + \" \" + word \n",
    "            \n",
    "        else: \n",
    "            if back == \"\": \n",
    "                back = word\n",
    "            else: \n",
    "                back = back + \" \" + word\n",
    "  \n",
    "  # divide every cases: e.g.\"repay our effort, time, attention etc...\" -> 1. repay our effort, 2.repay our time, 3. repay our attention\n",
    "    for i in process:\n",
    "        if front == \"\": \n",
    "            changed = i + \" \" + back\n",
    "        else: \n",
    "            changed = front + \" \" + i + \" \"+ back\n",
    "        ret.append(changed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of MWEs contain comma and etc:  137\n",
      "the number of MWEs after processed:  392\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of MWEs contain comma and etc: \",length)\n",
    "print(\"the number of MWEs after processed: \",len(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-6words: 0.9439427565623326\n",
      "2-9words: 0.9914670544118772\n",
      "26134\n",
      "25911\n"
     ]
    }
   ],
   "source": [
    "#phrases which contain 2-6 words account for 94.8% of whole phrase list\n",
    "#final MWE list contain MWEs which contain two or more words and nine or less words (99.1%) \n",
    "print('2-6words:',len([i for i in MWE_list if len(i.split())<7])/len(MWE_list))\n",
    "print('2-9words:',len([i for i in MWE_list if len(i.split())<10])/len(MWE_list))\n",
    "print(len(MWE_list))\n",
    "MWE_list=[i for i in MWE_list if len(i.split())<10]\n",
    "print(len(MWE_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "MWE_list_file=open('MWE_list.txt','w',encoding='utf-8')\n",
    "for i in MWE_list:\n",
    "    MWE_list_file.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code lemmatise phrase_list by using wn.morphy which is a function in wordnet that lemmatise word\n",
    "from nltk.corpus import wordnet as wn\n",
    "original_phrase=[i.split() for i in MWE_list]\n",
    "lemma_phrase=[]\n",
    "for i in original_phrase:\n",
    "    lemma_phrase_sen=[]\n",
    "    for j in i:\n",
    "        lemma_phrase_sen.append(wn.morphy(j))\n",
    "    lemma_phrase.append(lemma_phrase_sen)\n",
    "for i,y in zip(lemma_phrase,original_phrase):\n",
    "    for j,x in enumerate(i):\n",
    "        if x==None:\n",
    "            i[j]=y[j] \n",
    "\n",
    "lemma_phrase_list=[]\n",
    "for i in lemma_phrase:\n",
    "    lemma_phrase_list.append(' '.join(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since wn.morphy function can't handle -ing form, these are processed in a manual way.\n",
    "#and other errors such as 'wa', 'ha','are', 'am' are detected so changed it manually\n",
    "exception=['going',\n",
    " 'anything',\n",
    " 'being',\n",
    " 'nothing',\n",
    " 'everything',\n",
    " 'bring',\n",
    " 'getting',\n",
    " 'coming',\n",
    " 'looking',\n",
    " 'talking',\n",
    " 'morning',\n",
    " 'saying',\n",
    " 'working',\n",
    " 'making',\n",
    " 'thinking',\n",
    " 'taking',\n",
    " 'meeting',\n",
    " 'during',\n",
    " 'telling',\n",
    " 'running',\n",
    " 'feeling',\n",
    " 'building',\n",
    " 'fucking',\n",
    " 'living',\n",
    " 'waiting',\n",
    " 'using',\n",
    " 'playing',\n",
    " 'leaving',\n",
    " 'asking',\n",
    " 'giving',\n",
    " 'seeing',\n",
    " 'calling',\n",
    " 'following',\n",
    " 'happening',\n",
    " 'watching',\n",
    " 'wedding',\n",
    " 'sitting',\n",
    " 'lying',\n",
    " 'wearing',\n",
    " 'standing',\n",
    " 'training',\n",
    " 'putting',\n",
    " 'holding',\n",
    " 'starting',\n",
    " 'beginning',\n",
    " 'reading',\n",
    " 'walking',\n",
    " 'killing',\n",
    " 'driving',\n",
    " 'planning',\n",
    " 'fighting',\n",
    " 'keeping',\n",
    " 'darling',\n",
    " 'speaking',\n",
    " 'writing',\n",
    " 'helping',\n",
    " 'eating',\n",
    " 'finding',\n",
    " 'dying',\n",
    " 'hearing',\n",
    " 'listening',\n",
    " 'sing',\n",
    " 'crying',\n",
    " 'sleeping',\n",
    " 'drinking',\n",
    " 'willing',\n",
    " 'meaning',\n",
    " 'knowing',\n",
    " 'growing',\n",
    " 'acting',\n",
    " 'bringing',\n",
    " 'turning',\n",
    " 'screaming',\n",
    " 'opening',\n",
    " 'hanging',\n",
    " 'spring',\n",
    " 'painting',\n",
    " 'flying',\n",
    " 'selling',\n",
    " 'showing',\n",
    " 'leading',\n",
    " 'letting',\n",
    " 'hiding',\n",
    " 'shooting',\n",
    " 'dealing',\n",
    " 'breaking',\n",
    " 'setting',\n",
    " 'learning',\n",
    " 'understanding',\n",
    " 'buying',\n",
    " 'dating',\n",
    " 'heading',\n",
    " 'teaching',\n",
    " 'spending',\n",
    " 'singing',\n",
    " 'warning',\n",
    " 'sending',\n",
    " 'dancing',\n",
    " 'drawing',\n",
    " 'saving',\n",
    " 'winning',\n",
    " 'shopping',\n",
    " 'picking',\n",
    " 'cooking',\n",
    " 'cutting',\n",
    " 'pulling',\n",
    " 'offering',\n",
    " 'boring',\n",
    " 'burning',\n",
    " 'passing',\n",
    " 'housing',\n",
    " 'parking',\n",
    " 'breathing',\n",
    " 'recording',\n",
    " 'cleaning',\n",
    " 'panting',\n",
    " 'bleeding',\n",
    " 'suffering',\n",
    " 'cheering',\n",
    " 'hunting',\n",
    " 'riding',\n",
    " 'fishing',\n",
    " 'pushing',\n",
    " 'smoking',\n",
    " 'stealing',\n",
    " 'testing',\n",
    " 'closing',\n",
    " 'knocking',\n",
    " 'facing',\n",
    " 'engineering',\n",
    " 'string',\n",
    " 'covering',\n",
    " 'beating',\n",
    " 'yelling',\n",
    " 'landing',\n",
    " 'ending',\n",
    " 'developing',\n",
    " 'hitting',\n",
    " 'rising',\n",
    " 'stopping',\n",
    " 'studying',\n",
    " 'rolling',\n",
    " 'swimming',\n",
    " 'causing',\n",
    " 'serving',\n",
    " 'sharing',\n",
    " 'visiting',\n",
    " 'timing',\n",
    " 'shouting',\n",
    " 'whispering',\n",
    " 'trading',\n",
    " 'sobbing',\n",
    " 'digging',\n",
    " 'smiling',\n",
    " 'guessing',\n",
    " 'seeking',\n",
    " 'wasting',\n",
    " 'feeding',\n",
    " 'joining',\n",
    " 'counting',\n",
    " 'marketing',\n",
    " 'raising',\n",
    " 'racing',\n",
    " 'dressing',\n",
    " 'investigating',\n",
    " 'hurting',\n",
    " 'handling',\n",
    " 'growling',\n",
    " 'cheating',\n",
    " 'kissing',\n",
    " 'pretending',\n",
    " 'bearing',\n",
    " 'annoying',\n",
    " 'touching',\n",
    " 'funding',\n",
    " 'tracking',\n",
    " 'blowing',\n",
    " 'advertising',\n",
    " 'washing',\n",
    " 'firing',\n",
    " 'ringing',\n",
    " 'reaching',\n",
    " 'catching',\n",
    " 'travelling',\n",
    " 'filling',\n",
    " 'crossing',\n",
    " 'thanksgiving',\n",
    " 'kicking',\n",
    " 'ceiling',\n",
    " 'processing',\n",
    " 'coughing',\n",
    " 'arguing',\n",
    " 'worrying',\n",
    " 'entering',\n",
    " 'clothing',\n",
    " 'questioning',\n",
    " 'jumping',\n",
    " 'shaking',\n",
    " 'approaching',\n",
    " 'reporting',\n",
    " 'signing',\n",
    " 'dining',\n",
    " 'begging',\n",
    " 'ruling',\n",
    " 'failing',\n",
    " 'voting',\n",
    " 'fitting',\n",
    " 'starving',\n",
    " 'accounting',\n",
    " 'nursing',\n",
    " 'manufacturing',\n",
    " 'gathering',\n",
    " 'blessing',\n",
    " 'supporting',\n",
    " 'laying',\n",
    " 'climbing',\n",
    " 'outstanding',\n",
    " 'packing',\n",
    " 'floating',\n",
    " 'monitoring',\n",
    " 'judging',\n",
    " 'lightning',\n",
    " 'freezing',\n",
    " 'caring',\n",
    " 'finishing',\n",
    " 'pressing',\n",
    " 'gambling',\n",
    " 'performing',\n",
    " 'dreaming',\n",
    " 'kidnapping',\n",
    " 'believing',\n",
    " 'collecting',\n",
    " 'traveling',\n",
    " 'healing',\n",
    " 'pudding',\n",
    " 'attending',\n",
    " 'backing',\n",
    " 'lighting', 'wa','are','ha','am']\n",
    "\n",
    "def correction(text):\n",
    "    if text in exception:\n",
    "        text=re.sub('going','go',text)\n",
    "        text=re.sub('getting','get',text)\n",
    "        text=re.sub('coming','come',text)\n",
    "        text=re.sub('looking','look',text)\n",
    "        text=re.sub('talking','talk',text)\n",
    "        text=re.sub('saying','say',text)\n",
    "        text=re.sub('working','work',text)\n",
    "        text=re.sub('making','make',text)\n",
    "        text=re.sub('thinking','think',text)\n",
    "        text=re.sub('taking','take',text)\n",
    "        text=re.sub('meeting','meet',text)\n",
    "        text=re.sub('telling','tell',text)\n",
    "        text=re.sub('running','run',text)\n",
    "        text=re.sub('feeling','feel',text)\n",
    "        text=re.sub('fucking','fuck',text)\n",
    "        text=re.sub('living','live',text)\n",
    "        text=re.sub('waiting','wait',text)\n",
    "        text=re.sub('using','use',text)\n",
    "        text=re.sub('playing','play',text)\n",
    "        text=re.sub('leaving','leave',text)\n",
    "        text=re.sub('asking','ask',text)\n",
    "        text=re.sub('giving','give',text)\n",
    "        text=re.sub('seeing','see',text)\n",
    "        text=re.sub('calling','call',text)\n",
    "        text=re.sub('following','follow',text)\n",
    "        text=re.sub('happening','happen',text)\n",
    "        text=re.sub('watching','watch',text)\n",
    "        text=re.sub('sitting','sit',text)\n",
    "        text=re.sub('lying','lie',text)\n",
    "        text=re.sub('wearing','wear',text)\n",
    "        text=re.sub('standing','stand',text)\n",
    "        text=re.sub('training','train',text)\n",
    "        text=re.sub('putting','put',text)\n",
    "        text=re.sub('holding','hold',text)\n",
    "        text=re.sub('starting','start',text)\n",
    "        text=re.sub('beginning','begin',text)\n",
    "        text=re.sub('reading','read',text)\n",
    "        text=re.sub('walking','walk',text)\n",
    "        text=re.sub('killing','kill',text)\n",
    "        text=re.sub('driving','drive',text)\n",
    "        text=re.sub('planning','plan',text)\n",
    "        text=re.sub('fighting','fight',text)\n",
    "        text=re.sub('keeping','keep',text)\n",
    "        text=re.sub('speaking','speak',text)\n",
    "        text=re.sub('writing','write',text)\n",
    "        text=re.sub('helping','help',text)\n",
    "        text=re.sub('eating','eat',text)\n",
    "        text=re.sub('finding','find',text)\n",
    "        text=re.sub('dying','die',text)\n",
    "        text=re.sub('hearing','hear',text)\n",
    "        text=re.sub('listening','listen',text)\n",
    "        text=re.sub('crying','cry',text)\n",
    "        text=re.sub('sleeping','sleep',text)\n",
    "        text=re.sub('drinking', 'drink', text)\n",
    "        text=re.sub('meaning', 'mean', text)\n",
    "        text=re.sub('knowing','know',text)\n",
    "        text=re.sub('growing','grow',text)\n",
    "        text=re.sub('acting','act',text)\n",
    "        text=re.sub('bringing','bring',text)\n",
    "        text=re.sub('turning','turn',text)\n",
    "        text=re.sub('screaming','scream',text)\n",
    "        text=re.sub('opening','open',text)\n",
    "        text=re.sub('hanging', 'hang',text)\n",
    "        text=re.sub('painting', 'paint',text)\n",
    "        text=re.sub('flying', 'fly',text)\n",
    "        text=re.sub('selling', 'sell',text)\n",
    "        text=re.sub('showing', 'show',text)\n",
    "        text=re.sub('leading', 'lead',text)\n",
    "        text=re.sub('letting', 'let',text)\n",
    "        text=re.sub('hiding', 'hide',text)\n",
    "        text=re.sub('shooting', 'shoot',text)\n",
    "        text=re.sub('dealing', 'deal',text)\n",
    "        text=re.sub('breaking','break',text)\n",
    "        text=re.sub('setting', 'set',text)\n",
    "        text=re.sub('learning', 'learn',text)\n",
    "        text=re.sub('understanding', 'understand',text)\n",
    "        text=re.sub('buying','buy',text)\n",
    "        text=re.sub('dating', 'date',text)\n",
    "        text=re.sub('heading', 'head',text)\n",
    "        text=re.sub('teaching', 'teach',text)\n",
    "        text=re.sub('spending', 'spend',text)\n",
    "        text=re.sub('singing', 'sing',text)\n",
    "        text=re.sub('warning', 'warn',text)\n",
    "        text=re.sub('sending', 'send',text)\n",
    "        text=re.sub('dancing', 'dance',text)\n",
    "        text=re.sub('drawing', 'draw',text)\n",
    "        text=re.sub('saving', 'save',text)\n",
    "        text=re.sub('winning', 'win',text)\n",
    "        text=re.sub('shopping', 'shop',text)\n",
    "        text=re.sub('picking', 'pick',text)\n",
    "        text=re.sub('cooking', 'cook',text)\n",
    "        text=re.sub('cutting', 'cut',text)\n",
    "        text=re.sub('pulling', 'pull',text)\n",
    "        text=re.sub('offering', 'offer',text)\n",
    "    #text=re.sub('boring', 'bore', text)\n",
    "        text=re.sub('burning', 'burn',text)\n",
    "        text=re.sub('passing', 'pass',text)\n",
    "        text=re.sub('housing', 'house',text)\n",
    "        text=re.sub('parking', 'park',text)\n",
    "        text=re.sub('breathing', 'breathe',text)\n",
    "        text=re.sub('recording', 'record',text)\n",
    "        text=re.sub('cleaning', 'clean',text)\n",
    "        text=re.sub('panting', 'pant',text)\n",
    "        text=re.sub('bleeding', 'bleed',text)\n",
    "        text=re.sub('suffering', 'suffer',text)\n",
    "        text=re.sub('cheering', 'cheer',text)\n",
    "        text=re.sub('hunting', 'hunt',text)\n",
    "        text=re.sub('riding', 'ride',text)\n",
    "    # fishing->fish\n",
    "        text=re.sub('pushing', 'push',text)\n",
    "        text=re.sub('smoking', 'smoke',text)\n",
    "        text=re.sub('stealing', 'steal',text)\n",
    "        text=re.sub('testing', 'test',text)\n",
    "        text=re.sub('closing', 'close',text)\n",
    "        text=re.sub('knocking', 'knock',text)\n",
    "        text=re.sub('facing', 'face',text)\n",
    "    #text=re.sub('engineering', 'engineer',text)\n",
    "        text=re.sub('covering', 'cover',text)\n",
    "        text=re.sub('beating', 'beat',text)\n",
    "        text=re.sub('yelling', 'yell',text)\n",
    "    #text=re.sub('landing', 'land',text)\n",
    "        text=re.sub('ending', 'end',text)\n",
    "        text=re.sub('developing', 'develop',text)\n",
    "        text=re.sub('hitting', 'hit',text)\n",
    "        text=re.sub('rising', 'rise',text)\n",
    "        text=re.sub('stopping', 'stop',text)\n",
    "        text=re.sub('studying', 'study',text)\n",
    "        text=re.sub('rolling', 'roll',text)\n",
    "        text=re.sub('swimming', 'swim',text)\n",
    "        text=re.sub('causing', 'cause',text)\n",
    "        text=re.sub('serving', 'serve',text)\n",
    "        text=re.sub('sharing', 'share',text)\n",
    "        text=re.sub('visiting', 'visit',text)\n",
    "        text=re.sub('shouting', 'shout',text)\n",
    "        text=re.sub('whispering', 'whisper',text)\n",
    "        text=re.sub('trading', 'trade',text)\n",
    "        text=re.sub('sobbing', 'sob',text)\n",
    "        text=re.sub('digging', 'dig',text)\n",
    "        text=re.sub('smiling', 'smile',text)\n",
    "        text=re.sub('guessing', 'guess',text)\n",
    "        text=re.sub('seeking', 'seek',text)\n",
    "    #timing->time\n",
    "        text=re.sub('wasting', 'waste', text)\n",
    "        text=re.sub('feeding', 'feed', text)\n",
    "        text=re.sub('joining', 'join',text)\n",
    "        text=re.sub('counting', 'count',text)\n",
    "        text=re.sub('marketing', 'market',text)\n",
    "        text=re.sub('raising', 'raise',text)\n",
    "        text=re.sub('racing', 'race',text)\n",
    "        text=re.sub('dressing', 'dress',text)\n",
    "        text=re.sub('investigating', 'investigate',text)\n",
    "        text=re.sub('hurting','hurt',text)\n",
    "        text=re.sub('handling', 'handle',text)\n",
    "        text=re.sub('growling', 'growl',text)\n",
    "        text=re.sub('cheating', 'cheat',text)\n",
    "        text=re.sub('kissing', 'kiss',text)\n",
    "        text=re.sub('pretending','pretend',text)\n",
    "        text=re.sub('bearing', 'bear',text)\n",
    "        text=re.sub('annoying','annoy',text)\n",
    "        text=re.sub('touching', 'touch',text)\n",
    "        text=re.sub('funding', 'fund',text)\n",
    "        text=re.sub('tracking', 'track',text)\n",
    "        text=re.sub('blowing', 'blow',text)\n",
    "        text=re.sub('advertising','advertise',text)\n",
    "        text=re.sub('washing','wash',text)\n",
    "        text=re.sub('firing', 'fire',text)\n",
    "        text=re.sub('ringing', 'ring',text)\n",
    "        text=re.sub('reaching', 'reach',text)\n",
    "        text=re.sub('catching', 'catch',text)\n",
    "        text=re.sub('travelling', 'travel',text)\n",
    "        text=re.sub('filling', 'fill',text)\n",
    "        text=re.sub('crossing', 'cross',text)\n",
    "        text=re.sub('kicking', 'kick',text)\n",
    "        text=re.sub('processing', 'process',text)\n",
    "        text=re.sub('coughing', 'cough',text)\n",
    "        text=re.sub('arguing', 'argue',text)\n",
    "        text=re.sub('worrying', 'worry',text)\n",
    "        text=re.sub('entering', 'enter',text)\n",
    "     #clothing->clothe\n",
    "        text=re.sub('questioning', 'question',text)\n",
    "        text=re.sub('jumping', 'jump',text)\n",
    "        text=re.sub('shaking', 'shake',text)\n",
    "        text=re.sub('approaching', 'approach',text)\n",
    "        text=re.sub('reporting', 'report',text)\n",
    "        text=re.sub('signing','sign',text)\n",
    "        text=re.sub('dining','dine',text)\n",
    "        text=re.sub('begging', 'beg',text)\n",
    "        text=re.sub('ruling', 'rule',text)\n",
    "        text=re.sub('failing', 'fail',text)\n",
    "        text=re.sub('voting', 'vote',text)\n",
    "        text=re.sub('fitting', 'fit',text)\n",
    "        text=re.sub('starving', 'starve',text)\n",
    "    #accounting->account\n",
    "        text=re.sub('nursing','nurse',text)\n",
    "        text=re.sub('manufacturing', 'manufacture',text)\n",
    "        text=re.sub('gathering', 'gather',text)\n",
    "        text=re.sub('blessing', 'bless',text)\n",
    "        text=re.sub('supporting','support',text)\n",
    "        text=re.sub('laying', 'lay',text)\n",
    "        text=re.sub('climbing','climb',text)\n",
    "        text=re.sub('packing', 'pack',text)\n",
    "        text=re.sub('floating', 'float',text)\n",
    "        text=re.sub('monitoring', 'monitor',text)\n",
    "        text=re.sub('judging', 'judge',text)\n",
    "        text=re.sub('freezing', 'freeze',text)\n",
    "        text=re.sub('caring', 'care',text)\n",
    "        text=re.sub('finishing', 'finish',text)\n",
    "        text=re.sub('pressing', 'press',text)\n",
    "        text=re.sub('gambling', 'gamble',text)\n",
    "        text=re.sub('performing', 'perform',text)\n",
    "        text=re.sub('dreaming', 'dream',text)\n",
    "        text=re.sub('kidnapping', 'kidnap',text)\n",
    "        text=re.sub('believing', 'believe',text)\n",
    "        text=re.sub('collecting', 'collect',text)\n",
    "        text=re.sub('traveling', 'travel',text)\n",
    "        text=re.sub('healing', 'heal',text)\n",
    "        text=re.sub('attending', 'attend',text)\n",
    "        text = re.sub(\"am\",\"be\",text)\n",
    "        text = re.sub(\"wa\",\"be\",text)\n",
    "        text = re.sub(\"are\",\"be\",text)\n",
    "        text = re.sub(\"ha\",\"have\",text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "corrected_phrases=[]\n",
    "for i in lemma_phrase_list:\n",
    "    corrected_phrase=[]\n",
    "    for j in i.split():\n",
    "        corrected_phrase.append(correction(j))\n",
    "    corrected_phrases.append(corrected_phrase)\n",
    "    \n",
    "corrected_phrases_list=[' '.join(i) for i in corrected_phrases]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25911"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_phrases_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_phrase_list_file=open('lemma_MWE_list.txt','w',encoding='utf-8')\n",
    "for i in corrected_phrases_list:\n",
    "    lemma_phrase_list_file.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
